{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Protein mapping based on protein-protein interaction (PPI)**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Project Overview**\n",
        "\n",
        "This workflow analyzes a high-confidence protein-protein interaction (PPI) network to identify functionally related protein clusters through node embedding and dimensionality reduction.\n",
        "\n",
        "**Key Steps**\n",
        "\n",
        "1. **PPI network data acquisition** : STRING v12.0 score>=0.7 data is acquired as a PPI network data.\n",
        "\n",
        "2. **Node Embedding with node2vec** : The node2vec algorithm is applied to the network. This process learns a low-dimensional vector representation (an \"embedding\") for each protein (node), capturing its topological neighborhood within the network.\n",
        "\n",
        "3. **Dimensionality Reduction** : The resulting high-dimensional embedding data is reduced to two dimensions for visualization, using an algorithm like UMAP.\n",
        "\n",
        "4. **Mapping and Visualization** : The 2D-embedded proteins are visualized on a scatter plot. To analyze the results, known proteins are mapped onto the plot and colored according to their Gene Ontology (GO) terms."
      ],
      "metadata": {
        "id": "gou_U9kUqB0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Requirements**"
      ],
      "metadata": {
        "id": "Figxp4kJz9FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anndata scanpy xlsxwriter ndex2 node2vec\n",
        "import ndex2\n",
        "import networkx as nx\n",
        "import anndata\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from collections import Counter\n",
        "from node2vec import Node2Vec"
      ],
      "metadata": {
        "id": "eYzZJT2SqQ11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Find the compornent of PPI network data**"
      ],
      "metadata": {
        "id": "geXaIJal43e7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data check\n",
        "with open('STRING_v12.0_0.7.cx', 'r') as f:\n",
        "    cx_json = json.load(f)\n",
        "\n",
        "for aspect in cx_json:\n",
        "    print(list(aspect.keys()))\n",
        "\n",
        "# Show the amount of nodes and edges\n",
        "for aspect in cx_json:\n",
        "    if 'nodes' in aspect:\n",
        "        print(f\"nodes: {len(aspect['nodes'])}\")\n",
        "    if 'edges' in aspect:\n",
        "        print(f\"edges: {len(aspect['edges'])}\")"
      ],
      "metadata": {
        "id": "yqSpvfHj48Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Convert network data(.cx) to graph data**"
      ],
      "metadata": {
        "id": "bQtBZ-ocZcEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "\n",
        "id_to_symbol = {}\n",
        "edges = []\n",
        "node_attrs = {}\n",
        "edge_attrs = {}\n",
        "\n",
        "for aspect in cx_json:\n",
        "    if 'nodes' in aspect:\n",
        "        for node in aspect['nodes']:\n",
        "            node_id = node['@id']\n",
        "            symbol = node.get('n', f\"node_{node_id}\")\n",
        "            id_to_symbol[node_id] = symbol\n",
        "    elif 'edges' in aspect:\n",
        "        edges = aspect['edges']\n",
        "    elif 'nodeAttributes' in aspect:\n",
        "        for attr in aspect['nodeAttributes']:\n",
        "            node_id = attr['po']\n",
        "            name = attr['n']\n",
        "            value = attr.get('v')\n",
        "            if node_id not in node_attrs:\n",
        "                node_attrs[node_id] = {}\n",
        "            node_attrs[node_id][name] = value\n",
        "    elif 'edgeAttributes' in aspect:\n",
        "        for attr in aspect['edgeAttributes']:\n",
        "            edge_id = attr['po']\n",
        "            name = attr['n']\n",
        "            value = attr.get('v')\n",
        "            if edge_id not in edge_attrs:\n",
        "                edge_attrs[edge_id] = {}\n",
        "            edge_attrs[edge_id][name] = value\n",
        "\n",
        "# Add nodes（set symbol as ID）\n",
        "for node_id, symbol in id_to_symbol.items():\n",
        "    attrs = node_attrs.get(node_id, {})\n",
        "    G.add_node(symbol, **attrs)\n",
        "\n",
        "# Add edges\n",
        "for edge in edges:\n",
        "    source_id = edge['s']\n",
        "    target_id = edge['t']\n",
        "    source_symbol = id_to_symbol.get(source_id)\n",
        "    target_symbol = id_to_symbol.get(target_id)\n",
        "    if source_symbol and target_symbol:\n",
        "        attrs = edge_attrs.get(edge['@id'], {})\n",
        "        G.add_edge(source_symbol, target_symbol, **attrs)\n",
        "\n",
        "# Result\n",
        "print(f\"Loaded graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")"
      ],
      "metadata": {
        "id": "hJlXs_-hZYkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Nodes embedding by Node2Vec**"
      ],
      "metadata": {
        "id": "g68nlY7la2_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Node2Vec instance\n",
        "node2vec = Node2Vec(G, dimensions=1024, walk_length=80, num_walks=10, p=2, q=1, workers=4)\n",
        "\n",
        "model = node2vec.fit(window=10, min_count=1, batch_words=4, seed=42)\n",
        "\n",
        "#print(len(model.wv))\n",
        "#print(model.wv.index_to_key[:10])\n",
        "\n",
        "# Save result\n",
        "model.wv.save_word2vec_format(\"node_embeddings.txt\")\n",
        "model.save(\"node2vec_model.model\")\n",
        "\n",
        "# Duplicate symbols check\n",
        "symbol_list = list(id_to_symbol.values())\n",
        "counter = Counter(symbol_list)\n",
        "duplicates = [s for s, count in counter.items() if count > 1]\n",
        "\n",
        "print(f\"Number of duplicate symbols : {len(duplicates)}\")\n",
        "print(f\"Examples : {duplicates[:5]}\")\n",
        "\n",
        "# Create embedding dataframe\n",
        "embedding_df = pd.DataFrame(\n",
        "    [model.wv[node] for node in model.wv.index_to_key],\n",
        "    index=model.wv.index_to_key\n",
        ")\n",
        "\n",
        "embedding_df.columns = [f\"dim_{i}\" for i in range(embedding_df.shape[1])]\n",
        "\n",
        "# Save as csv\n",
        "embedding_df.to_csv('STRING_0.7_gene_embeddings.csv')"
      ],
      "metadata": {
        "id": "ZfdHJZoEZYIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Directly input embedding data (skip Node2Vec process)**\n",
        "\n",
        "For those skipping the node2vec process, please input embedding data here."
      ],
      "metadata": {
        "id": "SiiLy9xYS0Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#network_df = pd.read_csv('STRING_0.7_gene_embeddings.csv', index_col=0)\n",
        "#print(network_df.head())"
      ],
      "metadata": {
        "id": "7bo5ELTtS051"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Preparation of data for mapping**"
      ],
      "metadata": {
        "id": "2NB1355aVHGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding data\n",
        "network_df = embedding_df.copy()\n",
        "#print(network_df.head())\n",
        "\n",
        "# Protein information\n",
        "protein_inf = pd.read_csv('protein.info.v12.0.csv')\n",
        "#print(protein_inf.head())\n",
        "\n",
        "# Highlighting gene\n",
        "mapping_inf = pd.read_csv('Mapping_gene_list.csv')\n",
        "#print(mapping_inf.head())\n",
        "\n",
        "\n",
        "# Convert Ensembl IDs to preferred gene names (dataframe correction)\n",
        "ensembl_rows = network_df.index[network_df.index.str.contains(\"ensembl:\")]\n",
        "print(f\"Number of Ensembl ID columns : {len(ensembl_rows)}\")\n",
        "\n",
        "protein_inf = protein_inf.copy()\n",
        "protein_inf[\"clean_id\"] = protein_inf[\"#string_protein_id\"].str.replace(\"9606.\", \"\", regex=False)\n",
        "#print(protein_inf.head())\n",
        "id_to_name = protein_inf.set_index(\"clean_id\")[\"preferred_name\"].to_dict()\n",
        "#print(id_to_name)\n",
        "\n",
        "new_index = []\n",
        "for idx in network_df.index:\n",
        "    if \"ensembl:\" in idx:\n",
        "        ensp_id = idx.split(\":\")[1]\n",
        "        new_name = id_to_name.get(ensp_id, idx)\n",
        "        new_index.append(new_name)\n",
        "    else:\n",
        "        new_index.append(idx)\n",
        "\n",
        "network_df.index = new_index\n",
        "\n",
        "# Check result\n",
        "ensembl_rows = network_df.index[network_df.index.str.contains(\"ensembl:\")]\n",
        "print(f\"Number of Ensembl ID columns (after correction) : {len(ensembl_rows)}\")"
      ],
      "metadata": {
        "id": "nJx4RltJqRoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Add highlighting protein infomation to dataframe**"
      ],
      "metadata": {
        "id": "KkDPHGpdZPFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary of protein information\n",
        "mapping_dict = mapping_inf.to_dict('list')\n",
        "#print(mapping_dict)\n",
        "mapping_dict = {key: [item for item in value if pd.notna(item)] for key, value in mapping_dict.items()}\n",
        "for key, value in mapping_dict.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Add protein information column\n",
        "for group, gene_list in mapping_dict.items():\n",
        "    network_df[group] = network_df.index.isin(gene_list)\n",
        "\n",
        "# Create dataframe without protein infomation column\n",
        "network_numeric = network_df.iloc[:, :1024]  # Please set appropriate number of dimentions\n",
        "print(network_numeric.head())"
      ],
      "metadata": {
        "id": "6BZeepb4r2oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Reducing dimensions using UMAP and mapping**"
      ],
      "metadata": {
        "id": "SLVWvXY-ar9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UMAP\n",
        "reducer = umap.UMAP(n_components=2, random_state=42, min_dist=0.1, n_neighbors=6)\n",
        "embedding = reducer.fit_transform(network_numeric)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(\n",
        "    embedding[:, 0],\n",
        "    embedding[:, 1],\n",
        "    s=10,\n",
        "    alpha=0.5,\n",
        "    color='gray',\n",
        ")\n",
        "\n",
        "highlight_colors = {\n",
        "    'mitochondrial inner membrane': 'red',\n",
        "    'DNA replication': 'blue',\n",
        "    'trans-golgi network': 'green',\n",
        "    'cis-golgi network': 'yellow'\n",
        "}\n",
        "\n",
        "for category, color in highlight_colors.items():\n",
        "    idx = network_df[category]\n",
        "\n",
        "    plt.scatter(\n",
        "        embedding[idx, 0],\n",
        "        embedding[idx, 1],\n",
        "        s=10,\n",
        "        alpha=1.0,\n",
        "        color=color,\n",
        "        label=category\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.title('STRING 0.7 to UMAP', fontsize=16)\n",
        "plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
        "plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oTpkmfA_zIrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Visualization with Plotly**"
      ],
      "metadata": {
        "id": "6chFAV2bcBCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_plotly = pd.DataFrame({\n",
        "    'UMAP1': embedding[:, 0],\n",
        "    'UMAP2': embedding[:, 1],\n",
        "    'HoverName': network_df.index\n",
        "},  index=network_df.index)\n",
        "\n",
        "df_plotly['Label'] = 'Other'\n",
        "\n",
        "# Set highlighting categories and colors\n",
        "highlight_colors = {\n",
        "    'mitochondrial inner membrane': 'red',\n",
        "    'DNA replication': 'blue',\n",
        "    'trans-golgi network': 'green',\n",
        "    'cis-golgi network': 'yellow'\n",
        "}\n",
        "\n",
        "# If a gene belongs to multiple categories, it will be overwritten by the last category in the dictionary\n",
        "for category in highlight_colors.keys():\n",
        "    idx = network_df[category]\n",
        "    df_plotly.loc[idx, 'Label'] = category\n",
        "\n",
        "color_map = {**highlight_colors, 'Other': 'lightgray'}\n",
        "\n",
        "fig = px.scatter(\n",
        "    df_plotly,\n",
        "    x='UMAP1',\n",
        "    y='UMAP2',\n",
        "    color='Label',\n",
        "    hover_name='HoverName',\n",
        "    color_discrete_map=color_map,\n",
        "    opacity=0.8,\n",
        "    render_mode='webgl'\n",
        ")\n",
        "\n",
        "# Graph layout\n",
        "fig.update_layout(\n",
        "    width=1000,\n",
        "    height=800,\n",
        "    title_text='STRING 0.7 to UMAP',\n",
        "    legend_title_text='Category'\n",
        ")\n",
        "\n",
        "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "g96cFIC-gg0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}